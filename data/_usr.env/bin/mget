#!/usr/bin/env bash
#
# Copyright 2015-2017 (c) Yousong Zhou
#
# Test
#
#	python -c 'd="".join(chr(i&0xff) for i in range(1024)); f=open("1024B", "wb"); f.write(d); f.close()'
#
# - test: download 1024B file in 1024 chunks
#

# "!/usr/bin/env bash -e" will on Linux complaining it could not find "bash -e"
set -e

__errmsg() {
	echo "$1" >&2
}

_mget_chunk() {
	local url="$1"; shift
	local outn="$1"; shift
	local chunk="$1"; shift
	local offset="$1"; shift
	local existing startpos remaining

	if [ ! -f "$outn" ]; then
		startpos="$offset"
		remaining="$chunk"
	else
		existing="$(stat -c "%s" "$outn")"
		if [ "$existing" -eq "$chunk" ]; then
			return 0
		elif [ "$existing" -gt "$chunk" ]; then
			return 255
		fi
		startpos="$(($offset + $existing))"
		remaining="$(($chunk - $existing))"
	fi

	__errmsg "mget: $outn: size $remaining from $startpos to $(($startpos + $remaining))"
	case "$mget_bin_type" in
		wget)
			"${mget_cmd[@]}" --tries=5 --no-verbose --start-pos="$startpos" -O- "$url" \
				| head -c "$remaining" \
				>>"$outn" 2>/dev/null &
			;;
		curl)
			"${mget_cmd[@]}" --retry 5 --silent --range "$startpos-$(($startpos+$remaining-1))" "$url" \
				>>"$outn" 2>/dev/null &
			;;
		*)
			return 1
			;;
	esac
	_MGET_PGIDS="$(jobs -p | tr '\n' ' ')"
}

_mget_url_file_size() {
	local url="$1"; shift
	local size

	case "$mget_bin_type" in
		wget)
			size="$("${mget_cmd[@]}" --spider "$url" 2>&1 | awk '/Length:/ { print $2 }')"
			;;
		curl)
			size="$("${mget_cmd[@]}" --head --silent "$url" | awk '/Content-Length:/ { gsub(/[^0-9]/, "", $2); LEN=$2 } END { print LEN }')"
			;;
		*)
			return 1
			;;
	esac

	if [ -n "$size" ] && [ "$size" -ge 0 ]; then
		echo "$size"
	else
		return 1
	fi
}

_mget_usage() {
	cat >&2 <<EOF
usage: mget [options] --url <url> --count <count> [[wget|curl] arg1 arg2]

Open multiple wget/curl processes to fetch <url>.  Each downloaded chunk
will be named with suffix .N with N starting from 1, ending with <count>

 --output <fn>      filename prefix (default to url basename)
 --pos-start <int>  zero-based start position (default to 0)
 --pos-end <int>    non-inclusive end position (default to Content-Length)
 --no-combine       keep <fn>.N as they are
 -h|--help          show this help text

Those arguments not part of mget will be passed to each wget/curl process

Examples

    mget curl --location --socks5-hostname localhost:1080 -H 'Cookie: oh-my' \\
		--url http://example.com/f.200M \\
		--count 32

EOF
}

_mget_chunk_done() {
	local outn="$1"; shift
	local chunk="$1"; shift
	local existing

	if [ ! -f "$outn" ]; then
		return 2
	else
		existing="$(stat -c "%s" "$outn")"
		if [ "$existing" -eq "$chunk" ]; then
			return 0
		elif [ "$existing" -lt "$chunk" ]; then
			return 1
		else
			return 3
		fi
	fi
}

_mget_all_chunk_done() {
	local pos width i suffix
	local _chunk _fixup
	local rc

	_fixup="$mget_fixup"
	pos="$mget_pos_start"
	width="${#mget_count}"
	i=1
	while [ "$pos" -lt "$mget_pos_end" ]; do
		suffix="$(printf "%0${width}d" "$i")"
		if [ "$_fixup" -gt 0 ]; then
			_chunk="$(($mget_chunk + 1))"
			_fixup="$(($_fixup - 1))"
		else
			_chunk="$mget_chunk"
		fi

		_mget_chunk_done "$mget_output.$suffix" "$_chunk"
		rc="$?"; [ "$rc" = 0 ] || return "$rc"

		pos="$(($pos + $_chunk))"
		i="$(($i + 1))"
	done
}

mget() {
	local _chunk _fixup
	local pos width i suffix
	local chunks
	local combine=1

	mget_count=
	mget_cmd=()
	mget_output=
	mget_url=
	mget_pos_start=0
	mget_pos_end=
	mget_total=
	mget_chunk=
	mget_fixup=
	while [ "$#" -gt 0 ]; do
		case "$1" in
			--url)
				mget_url="$2"
				shift 2
				;;
			--count)
				mget_count="$2"
				shift 2
				;;
			--output)
				mget_output="$2"
				shift 2
				;;
			--pos-start)
				mget_pos_start="$2"
				shift 2
				;;
			--pos-end)
				mget_pos_end="$2"
				shift 2
				;;
			--no-combine)
				combine=0
				shift 1
				;;
			-h|--help)
				_mget_usage
				return 0
				;;
			*)
				mget_cmd+=("$1")
				shift 1
				;;
		esac
	done
	if [ -z "$mget_url" -o -z "$mget_count" ]; then
		_mget_usage
		return 1
	fi
	if [ -z "$mget_cmd" ]; then
		mget_cmd=(wget)
	fi
	mget_bin_type="${mget_cmd[0]}"
	if [ "$mget_bin_type" = "wget" ]; then
		wget --help | grep -q -m1 -- --start-pos || {
			__errmsg "mget: the wget doesn't support --start-pos option."
			__errmsg "  please upgrade wget or use curl"
			return 1
		}
	fi

	# prefix of output filename
	if [ -z "$mget_output" ]; then
		mget_output="$(basename "$mget_url" | cut -f1 -d '?')"
	fi

	if [ -s "$mget_output" ]; then
		__errmsg "mget: already exists: $mget_output"
		return 1
	fi

	if [ -z "$mget_pos_end" ]; then
		mget_pos_end="$(_mget_url_file_size "$mget_url")" || {
			__errmsg "mget: cannot get download size of $mget_url"
			return 1
		}
	fi
	if [ "$mget_pos_start" -gt "$mget_pos_end" ]; then
		__errmsg "mget: position invalid: $mget_pos_start->$mget_pos_end"
		return 1
	fi
	# 'read' cannot be used in pipe because it will be executed in subshell
	# thus the result is not available to caller
	mget_total="$(($mget_pos_end - $mget_pos_start))"
	mget_chunk="$(($mget_total / $mget_count))"
	mget_fixup="$(($mget_total - $mget_chunk * $mget_count))"

	# sh must be used because zsh has shwordsplit off
	_MGET_PGIDS=''
	trap 'trap - INT; sh -c "for p in $_MGET_PGIDS; do kill -0 \$p &>/dev/null && kill \$p; done"' INT

	_fixup="$mget_fixup"
	pos="$mget_pos_start"
	width="${#mget_count}"
	i=1
	while [ "$pos" -lt "$mget_pos_end" ]; do
		suffix="$(printf "%0${width}d" "$i")"
		if [ "$_fixup" -gt 0 ]; then
			_chunk="$(($mget_chunk + 1))"
			_fixup="$(($_fixup - 1))"
		else
			_chunk="$mget_chunk"
		fi
		_mget_chunk "$mget_url" "$mget_output.$suffix" "$_chunk" "$pos"
		chunks="$chunks $mget_output.$suffix"
		pos="$(($pos + $_chunk))"
		i="$(($i + 1))"
	done
	wait
	trap - INT

	_mget_all_chunk_done && {
		if [ "$combine" -gt 0 ]; then
			# assumption: no space within each file
			cat $chunks >"$mget_output"
			rm -f $chunks
		fi
	}
}

mget "$@"
